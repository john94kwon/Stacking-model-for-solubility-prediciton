{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d528841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c65fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 2333\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(1)\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2da88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "NUMBER_EPOCHS = 10\n",
    "LEARNING_RATE = 1E-4\n",
    "WEIGHT_DECAY = 1E-4\n",
    "BATCH_SIZE = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# GCN parameters\n",
    "GCN_FEATURE_DIM = 30\n",
    "GCN_HIDDEN_DIM = 256\n",
    "GCN_OUTPUT_DIM = 64 \n",
    "\n",
    "# Attention parameters\n",
    "DENSE_DIM = 16\n",
    "ATTENTION_HEADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80726c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = (rowsum ** -0.5).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    result = r_mat_inv @ mx @ r_mat_inv\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb25172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(label_number, mean, std):\n",
    "\n",
    "    # len(sequence) * 23\n",
    "    blosum_matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Seed_storage_data\\\\GCN\\\\Blosum features\\\\' + str(label_number) + '.npy')\n",
    "    \n",
    "    # len(sequence) * 30\n",
    "    a7_matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Seed_storage_data\\\\GCN\\\\7A features\\\\' + str(label_number) + '.npy')\n",
    "    \n",
    "    \n",
    "    # len(sequence) * 33\n",
    "    coord_matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Seed_storage_data\\\\GCN\\\\A_carbon_coordinates\\\\' + str(label_number) + '.npy')\n",
    " \n",
    "\n",
    "    #print(label_number)\n",
    "    feature_matrix = np.concatenate([blosum_matrix,a7_matrix,coord_matrix], axis=1)\n",
    "    feature_matrix = (feature_matrix - mean) / std\n",
    "    part1 = feature_matrix[:,0:20]\n",
    "    part2 = feature_matrix[:,23:]\n",
    "    # len(sequence) * 30\n",
    "    feature_matrix = np.concatenate([part1,part2],axis=1)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2355c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values():\n",
    "    mean = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Scaling\\\\GCN\\\\mean_matrix.npy\")\n",
    "    std = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Scaling\\\\GCN\\\\std_matrix.npy\")\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb9ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(label_number): ###################################################################################1\n",
    "    matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Seed_storage_data\\\\GCN\\\\Contact_maps_12A\\\\' + str(label_number) + '.npy').astype(np.float32)\n",
    "    edge_matrix = normalize(matrix)\n",
    "    return edge_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b6ce1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.label = dataframe['Number'].values\n",
    "        self.solubility = dataframe['solubility'].values\n",
    "        self.mean, self.std = load_values()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence_label = self.label[index]\n",
    "        solubility = self.solubility[index]\n",
    "        # L * 30\n",
    "        sequence_feature = load_features(sequence_label, self.mean, self.std)\n",
    "        # L * L\n",
    "        sequence_graph = load_graph(sequence_label)\n",
    "        \n",
    "        return sequence_label, solubility, sequence_feature, sequence_graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solubility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4065a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = input @ self.weight    # X * W\n",
    "        output = adj @ support           # A * X * W\n",
    "        if self.bias is not None:        # A * X * W + b\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b16b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(GCN_FEATURE_DIM, GCN_HIDDEN_DIM)\n",
    "        self.ln1 = nn.LayerNorm(GCN_HIDDEN_DIM)\n",
    "        self.gc2 = GraphConvolution(GCN_HIDDEN_DIM, GCN_OUTPUT_DIM)\n",
    "        self.ln2 = nn.LayerNorm(GCN_OUTPUT_DIM)\n",
    "        self.relu1 = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.relu2 = nn.LeakyReLU(0.2,inplace=True)\n",
    "\n",
    "    def forward(self, x, adj):  \t\t\t# x.shape = (seq_len, GCN_FEATURE_DIM); adj.shape = (seq_len, seq_len)\n",
    "        x = self.gc1(x, adj)  \t\t\t\t# x.shape = (seq_len, GCN_HIDDEN_DIM)\n",
    "        x = self.relu1(self.ln1(x))\n",
    "        x = self.gc2(x, adj)\n",
    "        output = self.relu2(self.ln2(x))\t# output.shape = (seq_len, GCN_OUTPUT_DIM)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "884b78d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, dense_dim, n_heads):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.dense_dim)\n",
    "        self.fc2 = nn.Linear(self.dense_dim, self.n_heads)\n",
    "\n",
    "    def softmax(self, input, axis=1):\n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size) - 1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = torch.softmax(input_2d, dim=1)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size) - 1)\n",
    "\n",
    "    def forward(self, input):  \t\t\t\t# input.shape = (1, seq_len, input_dim)\n",
    "        x = torch.tanh(self.fc1(input))  \t# x.shape = (1, seq_len, dense_dim)\n",
    "        x = self.fc2(x)  \t\t\t\t\t# x.shape = (1, seq_len, attention_hops)\n",
    "        x = self.softmax(x, 1)\n",
    "        attention = x.transpose(1, 2)  \t\t# attention.shape = (1, attention_hops, seq_len)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db211fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN_model, self).__init__()\n",
    "\n",
    "        self.gcn = GCN()\n",
    "        self.attention = Attention(GCN_OUTPUT_DIM, DENSE_DIM, ATTENTION_HEADS)\n",
    "        self.fc_final = nn.Linear(GCN_OUTPUT_DIM, NUM_CLASSES)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    def forward(self, x, adj):  \t\t\t\t\t\t\t\t\t\t\t# x.shape = (seq_len, FEATURE_DIM); adj.shape = (seq_len, seq_len)\n",
    "        x = x.float()\n",
    "        x = self.gcn(x, adj)  \t\t\t\t\t\t\t\t\t\t\t\t# x.shape = (seq_len, GAT_OUTPUT_DIM)\n",
    "\n",
    "        x = x.unsqueeze(0).float()  \t\t\t\t\t\t\t\t\t\t# x.shape = (1, seq_len, GAT_OUTPUT_DIM)\n",
    "        att = self.attention(x)  \t\t\t\t\t\t\t\t\t\t\t# att.shape = (1, ATTENTION_HEADS, seq_len)\n",
    "        node_feature_embedding = att @ x \t\t\t\t\t\t\t\t\t# output.shape = (1, ATTENTION_HEADS, GAT_OUTPUT_DIM)\n",
    "        node_feature_embedding_avg = torch.sum(node_feature_embedding,\n",
    "                                               1) / self.attention.n_heads  # node_feature_embedding_avg.shape = (1, GAT_OUTPUT_DIM)\n",
    "        output = torch.sigmoid(self.fc_final(node_feature_embedding_avg))  \t# output.shape = (1, NUM_CLASSES)\n",
    "        output2 = self.fc_final(node_feature_embedding_avg)\n",
    "\n",
    "\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa4f4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_model = GCN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01de79b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "GCN_model_directory=\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Models\\\\GCN\\\\model.pkl\"\n",
    "GCN_model.load_state_dict(torch.load(GCN_model_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e8c4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pd.read_csv(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Seed_storage_data\\\\GCN\\\\Seed_solubility_testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3282e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label=[]\n",
    "list_pred=[]\n",
    "list_solubility=[]\n",
    "def test_models(all_dataframe):\n",
    "    print(\"split_seed: \", SEED)\n",
    "    sequence_label = all_dataframe['Number'].values\n",
    "    solubility = all_dataframe['solubility'].values\n",
    "    data_loader1 = DataLoader(dataset=ProDataset(all_dataframe), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    \n",
    "\n",
    "    for data in tqdm(data_loader1):\n",
    "        with torch.no_grad():\n",
    "            sequence_label, solubility, sequence_features, sequence_graphs = data\n",
    "            sequence_features = torch.squeeze(sequence_features)\n",
    "            sequence_graphs = torch.squeeze(sequence_graphs)\n",
    "            \n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                features = Variable(sequence_features.cuda())\n",
    "                graphs = Variable(sequence_graphs.cuda())\n",
    "                y_true = Variable(solubility.cuda())\n",
    "               \n",
    "            else:\n",
    "                features = Variable(sequence_features)\n",
    "                graphs = Variable(sequence_graphs)\n",
    "                y_true = Variable(solubility)\n",
    "            \n",
    "\n",
    "                                    \n",
    "            y_pred_GCN = GCN_model(features,graphs)\n",
    "            y_true = y_true.float()\n",
    "\n",
    "            y_pred_GCN = y_pred_GCN.cpu().detach().numpy().tolist()\n",
    "            list_pred.append(y_pred_GCN)\n",
    "            list_label.append(sequence_label)\n",
    "            list_solubility.append(solubility)\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9637a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_seed:  2333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.35it/s]\n"
     ]
    }
   ],
   "source": [
    "test_models(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0369deea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label_real=[]\n",
    "list_pred_real=[]\n",
    "list_solubility_real=[]\n",
    "\n",
    "\n",
    "for i in range(0,len(list_label)):\n",
    "    A=list_label[i].tolist()\n",
    "    list_label_real.append(A[0])\n",
    "    \n",
    "for j in range (0,len(list_pred)):\n",
    "    B=list_pred[j]\n",
    "    list_pred_real.append(B[0])\n",
    "    \n",
    "for k in range(0,len(list_solubility)):\n",
    "    C=list_solubility[k].tolist()\n",
    "    list_solubility_real.append(C[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8b0017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  prediction  solubility\n",
      "0      3    0.897140           1\n",
      "1      2    0.899269           1\n",
      "2      4    0.893965           1\n",
      "3      1    0.897140           1\n",
      "4      0    0.565545           1\n"
     ]
    }
   ],
   "source": [
    "columns=['label','prediction','solubility']\n",
    "df = pd.DataFrame(list(zip(list_label_real, list_pred_real,list_solubility_real)))\n",
    "df.columns = columns\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
