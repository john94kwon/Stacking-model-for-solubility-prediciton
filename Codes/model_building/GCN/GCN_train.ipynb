{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a3c0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.autograd import Variable\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#Base code retrieved from J Cheminform 13, 7 (2021). https://doi.org/10.1186/s13321-021-00488-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f401b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "SEED = 2333\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(1)\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530baf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "NUMBER_EPOCHS = 11\n",
    "LEARNING_RATE = 1E-4\n",
    "WEIGHT_DECAY = 1E-4\n",
    "BATCH_SIZE = 1\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# GCN parameters\n",
    "GCN_FEATURE_DIM = 30\n",
    "GCN_HIDDEN_DIM = 256\n",
    "GCN_OUTPUT_DIM = 64   \n",
    "# Attention parameters\n",
    "DENSE_DIM = 16\n",
    "ATTENTION_HEADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72d0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = (rowsum ** -0.5).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    result = r_mat_inv @ mx @ r_mat_inv\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675be563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(label_number, mean, std):\n",
    "    \n",
    "    # len(sequence) * 23\n",
    "    blosum_matrix = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Training\\\\GCN\\\\Blosum features\\\\\" + str(label_number) + '.npy')\n",
    "    \n",
    "    # len(sequence) * 30\n",
    "    a7_matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Training\\\\GCN\\\\7A features\\\\' + str(label_number) + '.npy')\n",
    "    \n",
    "    # len(sequence) * 33\n",
    "    coord_matrix = np.load('C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Training\\\\GCN\\\\Acarbon_coordinates_centered\\\\' + str(label_number) + '.npy')\n",
    " \n",
    "\n",
    "    #print(label_number)\n",
    "    feature_matrix = np.concatenate([blosum_matrix,a7_matrix,coord_matrix], axis=1)\n",
    "    feature_matrix = (feature_matrix - mean) / std\n",
    "    part1 = feature_matrix[:,0:20]\n",
    "    part2 = feature_matrix[:,23:]\n",
    "    # len(sequence) * 30\n",
    "    feature_matrix = np.concatenate([part1,part2],axis=1)\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c653a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_values():\n",
    "    mean = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Scaling\\\\GCN\\\\mean_matrix.npy\")\n",
    "    std = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Scaling\\\\GCN\\\\std_matrix.npy\")\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd51a493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(label_number): \n",
    "    matrix = np.load(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Training\\\\GCN\\\\Contact_maps_12A\\\\\" + str(label_number) + '.npy').astype(np.float32)\n",
    "    edge_matrix = normalize(matrix)\n",
    "    return edge_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fccbc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe):\n",
    "        self.label = dataframe['Number'].values\n",
    "        self.solubility = dataframe['solubility'].values\n",
    "        self.mean, self.std = load_values()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sequence_label = self.label[index]\n",
    "        solubility = self.solubility[index]\n",
    "        # L * 30\n",
    "        sequence_feature = load_features(sequence_label, self.mean, self.std)\n",
    "        # L * L\n",
    "        sequence_graph = load_graph(sequence_label)\n",
    "        return sequence_label, solubility, sequence_feature, sequence_graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.solubility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b806d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = input @ self.weight    # X * W\n",
    "        output = adj @ support           # A * X * W\n",
    "        if self.bias is not None:        # A * X * W + b\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2be2bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(GCN_FEATURE_DIM, GCN_HIDDEN_DIM)\n",
    "        self.ln1 = nn.LayerNorm(GCN_HIDDEN_DIM)\n",
    "        self.gc2 = GraphConvolution(GCN_HIDDEN_DIM, GCN_OUTPUT_DIM)\n",
    "        self.ln2 = nn.LayerNorm(GCN_OUTPUT_DIM)\n",
    "        self.relu1 = nn.LeakyReLU(0.2,inplace=True)\n",
    "        self.relu2 = nn.LeakyReLU(0.2,inplace=True)\n",
    "\n",
    "    def forward(self, x, adj):  \t\t\t# x.shape = (seq_len, GCN_FEATURE_DIM); adj.shape = (seq_len, seq_len)\n",
    "        x = self.gc1(x, adj)  \t\t\t\t# x.shape = (seq_len, GCN_HIDDEN_DIM)\n",
    "        x = self.relu1(self.ln1(x))\n",
    "        x = self.gc2(x, adj)\n",
    "        output = self.relu2(self.ln2(x))\t# output.shape = (seq_len, GCN_OUTPUT_DIM)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8aec24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim, dense_dim, n_heads):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.fc1 = nn.Linear(self.input_dim, self.dense_dim)\n",
    "        self.fc2 = nn.Linear(self.dense_dim, self.n_heads)\n",
    "\n",
    "    def softmax(self, input, axis=1):\n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size) - 1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = torch.softmax(input_2d, dim=1)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size) - 1)\n",
    "\n",
    "    def forward(self, input):  \t\t\t\t# input.shape = (1, seq_len, input_dim)\n",
    "        x = torch.tanh(self.fc1(input))  \t# x.shape = (1, seq_len, dense_dim)\n",
    "        x = self.fc2(x)  \t\t\t\t\t# x.shape = (1, seq_len, attention_hops)\n",
    "        x = self.softmax(x, 1)\n",
    "        attention = x.transpose(1, 2)  \t\t# attention.shape = (1, attention_hops, seq_len)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2eee584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.gcn = GCN()\n",
    "        self.attention = Attention(GCN_OUTPUT_DIM, DENSE_DIM, ATTENTION_HEADS)\n",
    "        self.fc_final = nn.Linear(GCN_OUTPUT_DIM, NUM_CLASSES)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    def forward(self, x, adj):  \t\t\t\t\t\t\t\t\t\t\t# x.shape = (seq_len, FEATURE_DIM); adj.shape = (seq_len, seq_len)\n",
    "        x = x.float()\n",
    "        x = self.gcn(x, adj)  \t\t\t\t\t\t\t\t\t\t\t\t# x.shape = (seq_len, GAT_OUTPUT_DIM)\n",
    "\n",
    "        x = x.unsqueeze(0).float()  \t\t\t\t\t\t\t\t\t\t# x.shape = (1, seq_len, GAT_OUTPUT_DIM)\n",
    "        att = self.attention(x)  \t\t\t\t\t\t\t\t\t\t\t# att.shape = (1, ATTENTION_HEADS, seq_len)\n",
    "        node_feature_embedding = att @ x \t\t\t\t\t\t\t\t\t# output.shape = (1, ATTENTION_HEADS, GAT_OUTPUT_DIM)\n",
    "        node_feature_embedding_avg = torch.sum(node_feature_embedding,\n",
    "                                               1) / self.attention.n_heads  # node_feature_embedding_avg.shape = (1, GAT_OUTPUT_DIM)\n",
    "        output = torch.sigmoid(self.fc_final(node_feature_embedding_avg))  \t# output.shape = (1, NUM_CLASSES)\n",
    "        return output.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "137749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, epoch):\n",
    "\n",
    "    epoch_loss_train = 0.0\n",
    "    n_batches = 0\n",
    "    for data in tqdm(data_loader):\n",
    "        model.optimizer.zero_grad()\n",
    "        _, solubility, sequence_features, sequence_graphs = data\n",
    "\n",
    "        sequence_features = torch.squeeze(sequence_features)\n",
    "        sequence_graphs = torch.squeeze(sequence_graphs)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            features = Variable(sequence_features.cuda())\n",
    "            graphs = Variable(sequence_graphs.cuda())\n",
    "            y_true = Variable(solubility.cuda())\n",
    "        else:\n",
    "            features = Variable(sequence_features)\n",
    "            graphs = Variable(sequence_graphs)\n",
    "            y_true = Variable(solubility)\n",
    "\n",
    "        y_pred = model(features, graphs)\n",
    "        y_true = y_true.float()\n",
    "\n",
    "        # calculate loss\n",
    "        loss = model.criterion(y_pred, y_true)\n",
    "\n",
    "        # backward gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # update all parameters\n",
    "        model.optimizer.step()\n",
    "\n",
    "        epoch_loss_train += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    epoch_loss_train_avg = epoch_loss_train / n_batches\n",
    "    return epoch_loss_train_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a16e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "    valid_pred = []\n",
    "    valid_true = []\n",
    "    valid_label= []\n",
    "\n",
    "    for data in tqdm(data_loader):\n",
    "        with torch.no_grad():\n",
    "            sequence_label, solubility, sequence_features, sequence_graphs = data\n",
    "            sequence_features = torch.squeeze(sequence_features)\n",
    "            sequence_graphs = torch.squeeze(sequence_graphs)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                features = Variable(sequence_features.cuda())\n",
    "                graphs = Variable(sequence_graphs.cuda())\n",
    "                y_true = Variable(solubility.cuda())\n",
    "            else:\n",
    "                features = Variable(sequence_features)\n",
    "                graphs = Variable(sequence_graphs)\n",
    "                y_true = Variable(solubility)\n",
    "\n",
    "            y_pred = model(features, graphs)\n",
    "            y_true = y_true.float()\n",
    "\n",
    "            loss = model.criterion(y_pred, y_true)\n",
    "            y_pred = y_pred.cpu().detach().numpy().tolist()\n",
    "            y_true = y_true.cpu().detach().numpy().tolist()\n",
    "            valid_pred.extend(y_pred)\n",
    "            valid_true.extend(y_true)\n",
    "            valid_label.extend(sequence_label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "    epoch_loss_avg = epoch_loss / n_batches\n",
    "\n",
    "    return epoch_loss_avg, valid_true, valid_pred, valid_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42148a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataframe):\n",
    "    train_loader = DataLoader(dataset=ProDataset(train_dataframe), batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "    train_losses = []\n",
    "    train_pearson = []\n",
    "    train_r2 = []\n",
    "    train_binary_acc = []\n",
    "    train_precision = []\n",
    "    train_recall = []\n",
    "    train_f1 = []\n",
    "    train_auc = []\n",
    "    train_mcc = []\n",
    "    train_sensitivity = []\n",
    "    train_specificity = []\n",
    "\n",
    "    best_val_loss = 1000\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(NUMBER_EPOCHS+1):\n",
    "        print(\"\\n========== Train epoch \" + str(epoch + 1) + \" ==========\")\n",
    "        model.train()\n",
    "\n",
    "        epoch_loss_train_avg = train_one_epoch(model, train_loader, epoch + 1)\n",
    "        print(\"========== Evaluate Train set ==========\")\n",
    "        _, train_true, train_pred, train_label = evaluate(model, train_loader)\n",
    "        result_train = analysis(train_true, train_pred)\n",
    "        print(\"Train loss: \", np.sqrt(epoch_loss_train_avg))\n",
    "        print(\"Train pearson:\", result_train['pearson'])\n",
    "        print(\"Train r2:\", result_train['r2'])\n",
    "        print(\"Train binary acc: \", result_train['binary_acc'])\n",
    "        print(\"Train precision: \", result_train['precision'])\n",
    "        print(\"Train recall: \", result_train['recall'])\n",
    "        print(\"Train F1: \", result_train['f1'])\n",
    "        print(\"Train auc: \", result_train['auc'])\n",
    "        print(\"Train mcc: \", result_train['mcc'])\n",
    "        print(\"Train sensitivity: \", result_train['sensitivity'])\n",
    "        print(\"Train specificity: \", result_train['specificity'])\n",
    "\n",
    "        train_losses.append(np.sqrt(epoch_loss_train_avg))\n",
    "        train_pearson.append(result_train['pearson'])\n",
    "        train_r2.append(result_train['r2'])\n",
    "        train_binary_acc.append(result_train['binary_acc'])\n",
    "        train_precision.append(result_train['precision'])\n",
    "        train_recall.append(result_train['recall'])\n",
    "        train_f1.append(result_train['f1'])\n",
    "        train_auc.append(result_train['auc'])\n",
    "        train_mcc.append(result_train['mcc'])\n",
    "        train_sensitivity.append(result_train['sensitivity'])\n",
    "        train_specificity.append(result_train['specificity'])\n",
    "        print(epoch)\n",
    "        print(NUMBER_EPOCHS)\n",
    "\n",
    "        if epoch==NUMBER_EPOCHS:\n",
    "            torch.save(model.state_dict(), os.path.join(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Models\\\\GCN\\\\model.pkl\"))\n",
    "            ##############################2############################\n",
    "            \n",
    "                        \n",
    "            train_label2 = [tensor.item() for tensor in train_label]     \n",
    "            train_detail_dataframe = pd.DataFrame({'gene': train_label2, 'solubility': train_true, 'prediction': train_pred})\n",
    "            train_detail_dataframe.sort_values(by=['gene'], inplace=True)\n",
    "            train_detail_dataframe.to_csv(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Models\\\\GCN\\\\labels.csv\", header=True, sep=',')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0b09e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(y_true, y_pred):\n",
    "    binary_pred = [1 if pred >= 0.5 else 0 for pred in y_pred]\n",
    "    binary_true = [1 if true >= 0.5 else 0 for true in y_true]\n",
    "\n",
    "    # continous evaluate\n",
    "    pearson = pearsonr(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    # binary evaluate\n",
    "    binary_acc = metrics.accuracy_score(binary_true, binary_pred)\n",
    "    precision = metrics.precision_score(binary_true, binary_pred)\n",
    "    recall = metrics.recall_score(binary_true, binary_pred)\n",
    "    f1 = metrics.f1_score(binary_true, binary_pred)\n",
    "    auc = metrics.roc_auc_score(binary_true, y_pred)\n",
    "    mcc = metrics.matthews_corrcoef(binary_true, binary_pred)\n",
    "    TN, FP, FN, TP = metrics.confusion_matrix(binary_true, binary_pred).ravel()\n",
    "    sensitivity = 1.0 * TP / (TP + FN)\n",
    "    specificity = 1.0 * TN / (FP + TN)\n",
    "\n",
    "    result = {\n",
    "        'pearson': pearson,\n",
    "        'r2': r2,\n",
    "        'binary_acc': binary_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'mcc': mcc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7ca7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(all_dataframe):\n",
    "    print(\"split_seed: \", SEED)\n",
    "    sequence_label = all_dataframe['Number'].values\n",
    "    solubility = all_dataframe['solubility'].values\n",
    "    model=Model()\n",
    "    train(model, all_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9fe922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_seed:  2333\n",
      "\n",
      "========== Train epoch 1 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:44<00:00, 50.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:14<00:00, 157.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2728528337890776\n",
      "Train pearson: PearsonRResult(statistic=0.609776847936477, pvalue=6.233220136838449e-228)\n",
      "Train r2: 0.3173624861370459\n",
      "Train binary acc:  0.6960214573088959\n",
      "Train precision:  0.6206395348837209\n",
      "Train recall:  0.8438735177865613\n",
      "Train F1:  0.7152428810720269\n",
      "Train auc:  0.8129886262805517\n",
      "Train mcc:  0.42733166763269786\n",
      "Train sensitivity:  0.8438735177865613\n",
      "Train specificity:  0.5738775510204082\n",
      "0\n",
      "11\n",
      "\n",
      "========== Train epoch 2 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:21<00:00, 102.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:14<00:00, 152.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.25107292143392734\n",
      "Train pearson: PearsonRResult(statistic=0.6551089324114624, pvalue=2.0368669713426867e-274)\n",
      "Train r2: 0.42314764903423485\n",
      "Train binary acc:  0.7599463567277603\n",
      "Train precision:  0.7277085330776606\n",
      "Train recall:  0.75\n",
      "Train F1:  0.7386861313868615\n",
      "Train auc:  0.8338541582640961\n",
      "Train mcc:  0.516988168081731\n",
      "Train sensitivity:  0.75\n",
      "Train specificity:  0.7681632653061224\n",
      "1\n",
      "11\n",
      "\n",
      "========== Train epoch 3 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:23<00:00, 94.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:17<00:00, 125.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2452033730476617\n",
      "Train pearson: PearsonRResult(statistic=0.665546622778886, pvalue=2.745142802079885e-286)\n",
      "Train r2: 0.43231675144024917\n",
      "Train binary acc:  0.7697809566383549\n",
      "Train precision:  0.7872832369942196\n",
      "Train recall:  0.6729249011857708\n",
      "Train F1:  0.7256259989344699\n",
      "Train auc:  0.8386537065419053\n",
      "Train mcc:  0.5342481035863443\n",
      "Train sensitivity:  0.6729249011857708\n",
      "Train specificity:  0.8497959183673469\n",
      "2\n",
      "11\n",
      "\n",
      "========== Train epoch 4 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:58<00:00, 38.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:26<00:00, 85.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.24301232874993905\n",
      "Train pearson: PearsonRResult(statistic=0.6775757212820623, pvalue=1.4007003116961653e-300)\n",
      "Train r2: 0.45715298512170843\n",
      "Train binary acc:  0.7720160929816718\n",
      "Train precision:  0.7485148514851485\n",
      "Train recall:  0.7470355731225297\n",
      "Train F1:  0.7477744807121662\n",
      "Train auc:  0.8449044123578284\n",
      "Train mcc:  0.539782256392972\n",
      "Train sensitivity:  0.7470355731225297\n",
      "Train specificity:  0.7926530612244898\n",
      "3\n",
      "11\n",
      "\n",
      "========== Train epoch 5 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:49<00:00, 45.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:46<00:00, 48.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.24001959853802396\n",
      "Train pearson: PearsonRResult(statistic=0.6778857059404159, pvalue=5.874805986234772e-301)\n",
      "Train r2: 0.43325634386227574\n",
      "Train binary acc:  0.7603933839964238\n",
      "Train precision:  0.8035714285714286\n",
      "Train recall:  0.6225296442687747\n",
      "Train F1:  0.7015590200445435\n",
      "Train auc:  0.8445978865854642\n",
      "Train mcc:  0.5182776432816754\n",
      "Train sensitivity:  0.6225296442687747\n",
      "Train specificity:  0.8742857142857143\n",
      "4\n",
      "11\n",
      "\n",
      "========== Train epoch 6 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:54<00:00, 41.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:41<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.23877930414408646\n",
      "Train pearson: PearsonRResult(statistic=0.6877793558567131, pvalue=2.99022967694e-313)\n",
      "Train r2: 0.465493040336305\n",
      "Train binary acc:  0.7760393383996423\n",
      "Train precision:  0.7940161104718066\n",
      "Train recall:  0.6818181818181818\n",
      "Train F1:  0.7336523125996809\n",
      "Train auc:  0.848954585786884\n",
      "Train mcc:  0.5470456269223092\n",
      "Train sensitivity:  0.6818181818181818\n",
      "Train specificity:  0.8538775510204082\n",
      "5\n",
      "11\n",
      "\n",
      "========== Train epoch 7 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:46<00:00, 47.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:30<00:00, 73.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2360816222829709\n",
      "Train pearson: PearsonRResult(statistic=0.6988328403179848, pvalue=0.0)\n",
      "Train r2: 0.48644505891820544\n",
      "Train binary acc:  0.7791685292802861\n",
      "Train precision:  0.7709205020920502\n",
      "Train recall:  0.7282608695652174\n",
      "Train F1:  0.7489837398373983\n",
      "Train auc:  0.8543671856094216\n",
      "Train mcc:  0.5528545841818553\n",
      "Train sensitivity:  0.7282608695652174\n",
      "Train specificity:  0.8212244897959183\n",
      "6\n",
      "11\n",
      "\n",
      "========== Train epoch 8 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:24<00:00, 89.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:14<00:00, 154.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.23438836709235733\n",
      "Train pearson: PearsonRResult(statistic=0.6996594189647963, pvalue=0.0)\n",
      "Train r2: 0.45271488857404374\n",
      "Train binary acc:  0.7746982565936522\n",
      "Train precision:  0.8368700265251989\n",
      "Train recall:  0.6235177865612648\n",
      "Train F1:  0.7146092865232162\n",
      "Train auc:  0.8562079535371461\n",
      "Train mcc:  0.5508010527775292\n",
      "Train sensitivity:  0.6235177865612648\n",
      "Train specificity:  0.8995918367346939\n",
      "7\n",
      "11\n",
      "\n",
      "========== Train epoch 9 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:21<00:00, 105.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:14<00:00, 157.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.23247178755940903\n",
      "Train pearson: PearsonRResult(statistic=0.7038186248813415, pvalue=0.0)\n",
      "Train r2: 0.478769087778658\n",
      "Train binary acc:  0.7751452838623156\n",
      "Train precision:  0.7258207630878438\n",
      "Train recall:  0.808300395256917\n",
      "Train F1:  0.7648433847592333\n",
      "Train auc:  0.8588174558360895\n",
      "Train mcc:  0.5535450759110269\n",
      "Train sensitivity:  0.808300395256917\n",
      "Train specificity:  0.7477551020408163\n",
      "8\n",
      "11\n",
      "\n",
      "========== Train epoch 10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:21<00:00, 105.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:17<00:00, 131.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.23259520368047262\n",
      "Train pearson: PearsonRResult(statistic=0.7092844551276605, pvalue=0.0)\n",
      "Train r2: 0.48825099173680353\n",
      "Train binary acc:  0.7858739383102369\n",
      "Train precision:  0.8199279711884754\n",
      "Train recall:  0.674901185770751\n",
      "Train F1:  0.7403794037940379\n",
      "Train auc:  0.8618109219972573\n",
      "Train mcc:  0.5687834592773641\n",
      "Train sensitivity:  0.674901185770751\n",
      "Train specificity:  0.8775510204081632\n",
      "9\n",
      "11\n",
      "\n",
      "========== Train epoch 11 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:27<00:00, 81.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:18<00:00, 119.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.23010656228966714\n",
      "Train pearson: PearsonRResult(statistic=0.7173714558328508, pvalue=0.0)\n",
      "Train r2: 0.5102477482624519\n",
      "Train binary acc:  0.7872150201162271\n",
      "Train precision:  0.7809224318658281\n",
      "Train recall:  0.7361660079051383\n",
      "Train F1:  0.7578840284842319\n",
      "Train auc:  0.8645761071226911\n",
      "Train mcc:  0.569173512799439\n",
      "Train sensitivity:  0.7361660079051383\n",
      "Train specificity:  0.8293877551020408\n",
      "10\n",
      "11\n",
      "\n",
      "========== Train epoch 12 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:27<00:00, 82.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Evaluate Train set ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2237/2237 [00:17<00:00, 125.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.22899406818430298\n",
      "Train pearson: PearsonRResult(statistic=0.7163898758760975, pvalue=0.0)\n",
      "Train r2: 0.498115929694931\n",
      "Train binary acc:  0.7827447474295932\n",
      "Train precision:  0.7365107913669064\n",
      "Train recall:  0.8092885375494071\n",
      "Train F1:  0.7711864406779662\n",
      "Train auc:  0.8640687263047513\n",
      "Train mcc:  0.5675242091078807\n",
      "Train sensitivity:  0.8092885375494071\n",
      "Train specificity:  0.7608163265306123\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "train_dataframe = pd.read_csv(\"C:\\\\Users\\\\johnkwon\\\\Desktop\\\\[Ultima]_Solubility\\\\Data\\\\Ecoli_data\\\\Training\\\\GCN\\\\solubility_training.csv\")\n",
    "train_all(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbcfad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
